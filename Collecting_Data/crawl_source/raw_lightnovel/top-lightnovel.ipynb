{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"| **ATTRIBUTES**            |**MEANING**               |\n|:----------------------|:-------------------------------------------------------------|\n|**`Title`**            | Title of the manga (written in English phonetic)                                                |\n|**`Score`**            | Score on the MyAnimeList site (MAL)                                                             |\n|**`Vote`**             | Number of readers voting for the manga                                                          |\n|**`Ranked`**           | Ranking of manga on the web MyAnimeList (MAL)                                                   |\n|**`Popularity`**       | The popularity of the manga                                                                     |\n|**`Members`**          | Number of readers who have this manga in their list                                             |\n|**`Favorite`**         | Number of readers who love this manga                                                           |\n|**`Type`**\t\t        | Type (manga/manhwa/lightnovel...)                                                               |\n|**`Volumes`**          | Number of volumes of manga                                                                      |\n|**`Chapters`**         | Number of chapters of manga                                                                     |\n|**`Status`**           | Status of the manga (ongoing, completed, on hiatus,...)                                         |\n|**`Published`**        | Release time to the end time of the manga                                                       |\n|**`Genres`**           | Genres of manga                                                                                 |\n|**`Themes`**           | The themes of the manga                                                                         |\n|**`Demographics`** \t| Target demographic (e.g., Shounen).                                                             |\n|**`Serialization`** \t| Manga serialization information (e.g., Shounen Jump).                                           |\n|**`Author`**           | Author of manga                                                                                 |\n|**`Total Review`**     | Number of readers leaving comments on the manga                                                 |\n|**`Type Review`**      | Number of readers for each comment category (Recommended / Mixed feeling / Not recommended)     |","metadata":{}},{"cell_type":"code","source":"!pip install requests-html","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:00:20.593343Z","iopub.execute_input":"2024-11-19T10:00:20.594386Z","iopub.status.idle":"2024-11-19T10:00:34.354741Z","shell.execute_reply.started":"2024-11-19T10:00:20.594323Z","shell.execute_reply":"2024-11-19T10:00:34.353445Z"}},"outputs":[{"name":"stdout","text":"Collecting requests-html\n  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from requests-html) (2.32.3)\nCollecting pyquery (from requests-html)\n  Downloading pyquery-2.0.1-py3-none-any.whl.metadata (9.0 kB)\nCollecting fake-useragent (from requests-html)\n  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\nCollecting parse (from requests-html)\n  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\nCollecting bs4 (from requests-html)\n  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\nCollecting w3lib (from requests-html)\n  Downloading w3lib-2.2.1-py3-none-any.whl.metadata (2.1 kB)\nCollecting pyppeteer>=0.0.14 (from requests-html)\n  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\nRequirement already satisfied: certifi>=2023 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html) (2024.8.30)\nRequirement already satisfied: importlib-metadata>=1.4 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html) (7.0.0)\nCollecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\n  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: tqdm<5.0.0,>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html) (4.66.4)\nRequirement already satisfied: urllib3<2.0.0,>=1.25.8 in /opt/conda/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests-html) (1.26.18)\nCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from bs4->requests-html) (4.12.3)\nRequirement already satisfied: lxml>=2.1 in /opt/conda/lib/python3.10/site-packages (from pyquery->requests-html) (5.3.0)\nCollecting cssselect>=1.2.0 (from pyquery->requests-html)\n  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->requests-html) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->requests-html) (3.7)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.19.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->bs4->requests-html) (2.5)\nDownloading requests_html-0.10.0-py3-none-any.whl (13 kB)\nDownloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\nDownloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\nDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\nDownloading pyquery-2.0.1-py3-none-any.whl (22 kB)\nDownloading w3lib-2.2.1-py3-none-any.whl (21 kB)\nDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\nDownloading pyee-11.1.1-py3-none-any.whl (15 kB)\nDownloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: parse, fake-useragent, websockets, w3lib, pyee, cssselect, pyquery, pyppeteer, bs4, requests-html\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\nSuccessfully installed bs4-0.0.2 cssselect-1.2.0 fake-useragent-1.5.1 parse-1.20.2 pyee-11.1.1 pyppeteer-2.0.0 pyquery-2.0.1 requests-html-0.10.0 w3lib-2.2.1 websockets-10.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install lxml_html_clean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:00:34.357228Z","iopub.execute_input":"2024-11-19T10:00:34.357729Z","iopub.status.idle":"2024-11-19T10:00:44.648549Z","shell.execute_reply.started":"2024-11-19T10:00:34.357675Z","shell.execute_reply":"2024-11-19T10:00:44.647233Z"}},"outputs":[{"name":"stdout","text":"Collecting lxml_html_clean\n  Downloading lxml_html_clean-0.4.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from lxml_html_clean) (5.3.0)\nDownloading lxml_html_clean-0.4.1-py3-none-any.whl (14 kB)\nInstalling collected packages: lxml_html_clean\nSuccessfully installed lxml_html_clean-0.4.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import requests\nfrom requests_html import HTMLSession\nfrom bs4 import BeautifulSoup\nimport re\nimport nest_asyncio\nimport pandas as pd \nimport datetime\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:00:44.650040Z","iopub.execute_input":"2024-11-19T10:00:44.650407Z","iopub.status.idle":"2024-11-19T10:00:45.353439Z","shell.execute_reply.started":"2024-11-19T10:00:44.650368Z","shell.execute_reply":"2024-11-19T10:00:45.352601Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Crawl data URLS","metadata":{}},{"cell_type":"code","source":"nest_asyncio.apply() \nsession = HTMLSession()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:00:45.355350Z","iopub.execute_input":"2024-11-19T10:00:45.355835Z","iopub.status.idle":"2024-11-19T10:00:45.360998Z","shell.execute_reply.started":"2024-11-19T10:00:45.355802Z","shell.execute_reply":"2024-11-19T10:00:45.359982Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"listUrl1 = []\n\nfor i in range(0,7600,50):\n    # Url of the website to scrap\n    url = f'https://myanimelist.net/topmanga.php?type=lightnovels&limit={i}'\n\n    # Get the html content\n    html = requests.get(url).text\n\n    # Parse the html content\n    soup = BeautifulSoup(html, \"html.parser\")\n\n    # Get the list of manga\n    listItem = soup.find_all(\"td\", {\"class\": \"title al va-t clearfix word-break\"})\n\n    # Get the url of each manga\n    for item in listItem:\n        listUrl1.append(item.find('a').get('href'))\n\n    # Print the number of manga urls collected\n    print(f'{len(listUrl1)} urls collected', end='\\r', flush=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:00:45.362423Z","iopub.execute_input":"2024-11-19T10:00:45.362839Z","iopub.status.idle":"2024-11-19T10:01:44.261633Z","shell.execute_reply.started":"2024-11-19T10:00:45.362795Z","shell.execute_reply":"2024-11-19T10:01:44.260445Z"}},"outputs":[{"name":"stdout","text":"7600 urls collected\r","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"listUrl = listUrl1\nprint(f'Total: {len(listUrl)} urls collected')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:01:44.263247Z","iopub.execute_input":"2024-11-19T10:01:44.263562Z","iopub.status.idle":"2024-11-19T10:01:44.269607Z","shell.execute_reply.started":"2024-11-19T10:01:44.263531Z","shell.execute_reply":"2024-11-19T10:01:44.268511Z"}},"outputs":[{"name":"stdout","text":"Total: 7600 urls collected\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"with open(\"/kaggle/working/top_lightnovel_collecting.txt\", \"w\") as file:\n    file.writelines(item + \"\\n\" for item in listUrl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:01:44.270905Z","iopub.execute_input":"2024-11-19T10:01:44.271239Z","iopub.status.idle":"2024-11-19T10:01:44.291622Z","shell.execute_reply.started":"2024-11-19T10:01:44.271206Z","shell.execute_reply":"2024-11-19T10:01:44.290458Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Crawl HTML content from the manga/light novel/... URLs","metadata":{}},{"cell_type":"code","source":"listHtml1 = []\n\nfor url in listUrl[0:7600]:\n    res = session.get(url)\n    while len(res.text) < 4000:\n        # Sleep for 10 minutes\n        time.sleep(200)\n        res = session.get(url)\n        \n    listHtml1.append(res.text)\n\n    # Print the number of manga html collected\n    print(f'{len(listHtml1)}/{len(listUrl)} manga html collected', end='\\r', flush=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T10:01:44.293348Z","iopub.execute_input":"2024-11-19T10:01:44.293767Z","iopub.status.idle":"2024-11-19T12:00:11.664722Z","shell.execute_reply.started":"2024-11-19T10:01:44.293732Z","shell.execute_reply":"2024-11-19T12:00:11.663432Z"}},"outputs":[{"name":"stdout","text":"7600/7600 manga html collected\r","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Extract time of data collection to report for the project\nnow = datetime.datetime.now()\nnow = now.strftime(\"%Y-%m-%d\")\nprint(\"Time of data collection: \", now)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:00:11.666563Z","iopub.execute_input":"2024-11-19T12:00:11.667027Z","iopub.status.idle":"2024-11-19T12:00:11.675058Z","shell.execute_reply.started":"2024-11-19T12:00:11.666979Z","shell.execute_reply":"2024-11-19T12:00:11.673957Z"}},"outputs":[{"name":"stdout","text":"Time of data collection:  2024-11-19\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"listHtml = listHtml1\nprint(f'Total: {len(listHtml)} manga html collected')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:00:11.678593Z","iopub.execute_input":"2024-11-19T12:00:11.678976Z","iopub.status.idle":"2024-11-19T12:00:11.694047Z","shell.execute_reply.started":"2024-11-19T12:00:11.678940Z","shell.execute_reply":"2024-11-19T12:00:11.692707Z"}},"outputs":[{"name":"stdout","text":"Total: 7600 manga html collected\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def extract_info(htmlComic):\n    soup = BeautifulSoup(htmlComic, \"html.parser\")\n\n    title = soup.find('span', {'itemprop': 'name'})\n    if title is None:\n        return None\n    else:\n        title_text = title.text.strip()\n        title_english_span = title.find('span', {'class': 'title-english'})\n\n        if title_english_span is not None:\n            title_english_text = title_english_span.text.strip()\n            title_text = title_text.replace(title_english_text, '')\n            title = f'{title_text} ({title_english_text})'\n        else:\n            title = title_text\n    # ratingValue = soup.find('span', {'itemprop': 'ratingValue'}).text\n    # ratingCount = soup.find('span', {'itemprop': 'ratingCount'}).text\n    # ranked = re.findall(r'\\d+', soup.find('span', {'class': 'numbers ranked'}).text)[0]\n    ratingValue_tag = soup.find('span', {'itemprop': 'ratingValue'})\n    ratingValue = ratingValue_tag.text.strip() if ratingValue_tag else None\n    \n    ratingCount_tag = soup.find('span', {'itemprop': 'ratingCount'})\n    ratingCount = ratingCount_tag.text.strip() if ratingCount_tag else None\n    \n    # ranked_tag = soup.find('span', {'class': 'numbers ranked'})\n    # ranked = re.findall(r'\\d+', ranked_tag.text)[0] if ranked_tag else None\n    ranked_tag = soup.find('span', {'class': 'numbers ranked'})\n    if ranked_tag:\n        ranked_numbers = re.findall(r'\\d+', ranked_tag.text)\n        ranked = ranked_numbers[0] if ranked_numbers else None\n    else:\n        ranked = None\n    popularity = re.findall(r'\\d+', soup.find('span', {'class': 'numbers popularity'}).text)[0]\n\n    volumes, chapters, status, published = '', '', '', ''\n    genres, themes, authors, favorites, members = [], [], '', '', ''\n    type_, demographic, serialization = '', '', ''\n\n    for space in soup.find_all(\"div\", {'class': 'spaceit_pad'}):\n        text = space.text.strip()\n        \n        if 'Type:' in text:\n            type_ = text.split(':', 1)[1].strip()\n        elif 'Volumes:' in text:\n            volumes = text.split(':', 1)[1].strip()\n        elif 'Chapters:' in text:\n            chapters = text.split(':', 1)[1].strip()\n        elif 'Status:' in text:\n            # Lấy nội dung sau thẻ <span class=\"dark_text\">\n            status = space.find('span', {'class': 'dark_text'}).next_sibling.strip()\n        elif 'Published:' in text:\n            published = text.split(':', 1)[1].strip()\n        elif 'Genres:' in text or 'Genre:' in text:\n            genres = [gen.text.strip() for gen in space.find_all('a')]\n        elif 'Themes:' in text or 'Theme:' in text:\n            # Lấy cả giá trị từ <a> và <span itemprop=\"genre\">\n            themes = [theme.text.strip() for theme in space.find_all('a')]\n        elif 'Demographic:' in text or 'Demographics:' in text:\n            demographic = space.find('a').text.strip()\n        elif 'Serialization:' in text or 'Serializations:' in text:\n            # serialization = space.find('a').text.strip()\n            serialization_tag = space.find('a')  # Tìm thẻ <a>\n            serialization = serialization_tag.text.strip() if serialization_tag else ''  # Kiểm tra nếu không tìm thấy\n        elif 'Authors:' in text or 'Author:' in text:\n            authors = text.split(':')[1].strip()\n            # authors = space.find('a').text.strip()\n            # author_tag = space.find('a')  # Tìm thẻ <a>\n            # authors = author_tag.text.strip() if author_tag else ''  # Kiểm tra nếu không tìm thấy\n        elif 'Favorites:' in text:\n            favorites = text.split(':', 1)[1].strip()\n        elif 'Members:' in text:\n            members = text.split(':', 1)[1].strip()\n\n    infoReviews = soup.find('div', {'class': 'manga-info-review__header mal-navbar'})\n    totalReviews = re.findall(r'\\d+', infoReviews.find('div', {'class': 'right'}).text)[0]\n\n    typeReview = [\n        int(re.findall(r'\\d+', infoReviews.find('div', {'class': 'recommended'}).text)[0]),\n        int(re.findall(r'\\d+', infoReviews.find('div', {'class': 'mixed-feelings'}).text)[0]),\n        int(re.findall(r'\\d+', infoReviews.find('div', {'class': 'not-recommended'}).text)[0])\n    ]\n\n    return {\n        \"Title\": title, \"Score\": ratingValue, \"Vote\": ratingCount,\n        \"Ranked\": ranked, \"Popularity\": popularity, \"Members\": members,\n        \"Favorite\": favorites, \"Types\": type_, \"Volumes\": volumes, \n        \"Chapters\": chapters, \"Status\": status, \"Published\": published, \n        \"Genres\": genres, \"Themes\": themes, \"Demographic\": demographic, \"Serialization\": serialization, \n        \"Author\": authors, \"Total Review\": totalReviews, \"Type Review\": typeReview\n    }\n\n# data_list = [extract_info(htmlComic) for htmlComic in listHtml if extract_info(htmlComic) is not None]\n# df = pd.DataFrame(data_list)\ndata_list = []\nfor idx, htmlComic in enumerate(listHtml, start=1):\n    result = extract_info(htmlComic)\n    if result is not None:\n        data_list.append(result)\n    # In trạng thái sau khi duyệt mỗi phần tử\n    print(f\"Đã xử lý {idx}/{len(listHtml)} phần tử.\", end='\\r', flush=True)\n    # print(f'{len(listUrl1)} urls collected', end='\\r', flush=True)\n\ndf = pd.DataFrame(data_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:00:11.696009Z","iopub.execute_input":"2024-11-19T12:00:11.696408Z","iopub.status.idle":"2024-11-19T12:07:43.160575Z","shell.execute_reply.started":"2024-11-19T12:00:11.696375Z","shell.execute_reply":"2024-11-19T12:07:43.159471Z"}},"outputs":[{"name":"stdout","text":"Đã xử lý 7600/7600 phần tử.\r","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:07:43.162061Z","iopub.execute_input":"2024-11-19T12:07:43.162479Z","iopub.status.idle":"2024-11-19T12:07:43.200172Z","shell.execute_reply.started":"2024-11-19T12:07:43.162443Z","shell.execute_reply":"2024-11-19T12:07:43.199031Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                               Title Score   Vote Ranked  \\\n0                    Monogatari Series: First Season  8.91  16984     19   \n1                   Monogatari Series: Second Season  8.90   7579     23   \n2                    Monogatari Series: Final Season  8.83   5451     31   \n3  Mushoku Tensei: Isekai Ittara Honki Dasu (Mush...  8.82  39184     34   \n4               Ookami to Koushinryou (Spice & Wolf)  8.82  16497     35   \n\n  Popularity Members Favorite        Types  Volumes Chapters      Status  \\\n0        277  60,793    3,128  Light Novel        6      107    Finished   \n1        792  23,906      767  Light Novel        6      199    Finished   \n2        994  19,496      497  Light Novel        6      231    Finished   \n3        170  90,450    8,393  Light Novel       26      330    Finished   \n4        251  65,913    4,195  Light Novel  Unknown  Unknown  Publishing   \n\n                        Published  \\\n0   Nov  1, 2006 to Jul  28, 2010   \n1  Oct  27, 2010 to Dec  20, 2011   \n2  Sep  28, 2012 to Sep  18, 2014   \n3  Jan  23, 2014 to Nov  25, 2022   \n4              Feb  10, 2006 to ?   \n\n                                              Genres  \\\n0   [Action, Comedy, Mystery, Romance, Supernatural]   \n1             [Comedy, Drama, Mystery, Supernatural]   \n2                    [Comedy, Mystery, Supernatural]   \n3                                          [Fantasy]   \n4  [Adventure, Drama, Fantasy, Romance, Supernatu...   \n\n                     Themes Demographic Serialization  \\\n0                 [Vampire]                  Mephisto   \n1                 [Vampire]                             \n2                 [Vampire]                             \n3   [Isekai, Reincarnation]                             \n4  [Adult Cast, Historical]                             \n\n                                        Author Total Review Type Review  \n0             NISIO, ISIN (Story), VOFAN (Art)           14  [13, 1, 0]  \n1             NISIO, ISIN (Story), VOFAN (Art)            3   [3, 0, 0]  \n2             NISIO, ISIN (Story), VOFAN (Art)            0   [0, 0, 0]  \n3  Rifujin na Magonote (Story), Sirotaka (Art)           63  [47, 8, 8]  \n4  Hasekura, Isuna (Story), Ayakura, Juu (Art)           11  [11, 0, 0]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Score</th>\n      <th>Vote</th>\n      <th>Ranked</th>\n      <th>Popularity</th>\n      <th>Members</th>\n      <th>Favorite</th>\n      <th>Types</th>\n      <th>Volumes</th>\n      <th>Chapters</th>\n      <th>Status</th>\n      <th>Published</th>\n      <th>Genres</th>\n      <th>Themes</th>\n      <th>Demographic</th>\n      <th>Serialization</th>\n      <th>Author</th>\n      <th>Total Review</th>\n      <th>Type Review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Monogatari Series: First Season</td>\n      <td>8.91</td>\n      <td>16984</td>\n      <td>19</td>\n      <td>277</td>\n      <td>60,793</td>\n      <td>3,128</td>\n      <td>Light Novel</td>\n      <td>6</td>\n      <td>107</td>\n      <td>Finished</td>\n      <td>Nov  1, 2006 to Jul  28, 2010</td>\n      <td>[Action, Comedy, Mystery, Romance, Supernatural]</td>\n      <td>[Vampire]</td>\n      <td></td>\n      <td>Mephisto</td>\n      <td>NISIO, ISIN (Story), VOFAN (Art)</td>\n      <td>14</td>\n      <td>[13, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Monogatari Series: Second Season</td>\n      <td>8.90</td>\n      <td>7579</td>\n      <td>23</td>\n      <td>792</td>\n      <td>23,906</td>\n      <td>767</td>\n      <td>Light Novel</td>\n      <td>6</td>\n      <td>199</td>\n      <td>Finished</td>\n      <td>Oct  27, 2010 to Dec  20, 2011</td>\n      <td>[Comedy, Drama, Mystery, Supernatural]</td>\n      <td>[Vampire]</td>\n      <td></td>\n      <td></td>\n      <td>NISIO, ISIN (Story), VOFAN (Art)</td>\n      <td>3</td>\n      <td>[3, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Monogatari Series: Final Season</td>\n      <td>8.83</td>\n      <td>5451</td>\n      <td>31</td>\n      <td>994</td>\n      <td>19,496</td>\n      <td>497</td>\n      <td>Light Novel</td>\n      <td>6</td>\n      <td>231</td>\n      <td>Finished</td>\n      <td>Sep  28, 2012 to Sep  18, 2014</td>\n      <td>[Comedy, Mystery, Supernatural]</td>\n      <td>[Vampire]</td>\n      <td></td>\n      <td></td>\n      <td>NISIO, ISIN (Story), VOFAN (Art)</td>\n      <td>0</td>\n      <td>[0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mushoku Tensei: Isekai Ittara Honki Dasu (Mush...</td>\n      <td>8.82</td>\n      <td>39184</td>\n      <td>34</td>\n      <td>170</td>\n      <td>90,450</td>\n      <td>8,393</td>\n      <td>Light Novel</td>\n      <td>26</td>\n      <td>330</td>\n      <td>Finished</td>\n      <td>Jan  23, 2014 to Nov  25, 2022</td>\n      <td>[Fantasy]</td>\n      <td>[Isekai, Reincarnation]</td>\n      <td></td>\n      <td></td>\n      <td>Rifujin na Magonote (Story), Sirotaka (Art)</td>\n      <td>63</td>\n      <td>[47, 8, 8]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ookami to Koushinryou (Spice &amp; Wolf)</td>\n      <td>8.82</td>\n      <td>16497</td>\n      <td>35</td>\n      <td>251</td>\n      <td>65,913</td>\n      <td>4,195</td>\n      <td>Light Novel</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Publishing</td>\n      <td>Feb  10, 2006 to ?</td>\n      <td>[Adventure, Drama, Fantasy, Romance, Supernatu...</td>\n      <td>[Adult Cast, Historical]</td>\n      <td></td>\n      <td></td>\n      <td>Hasekura, Isuna (Story), Ayakura, Juu (Art)</td>\n      <td>11</td>\n      <td>[11, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"df.to_csv('/kaggle/working/raw_top_lightnovels.csv', encoding='utf-8-sig', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T12:07:43.202164Z","iopub.execute_input":"2024-11-19T12:07:43.202492Z","iopub.status.idle":"2024-11-19T12:07:43.346949Z","shell.execute_reply.started":"2024-11-19T12:07:43.202463Z","shell.execute_reply":"2024-11-19T12:07:43.345654Z"}},"outputs":[],"execution_count":13}]}